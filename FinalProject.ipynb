{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5240eaa4-467d-4b0e-bfd2-5d627e3ea3e4",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "In this project we will have three topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b02bb-c821-43af-8fc1-27d0150eeefe",
   "metadata": {},
   "source": [
    "1) Asteroid Spectral Classification Estimator: \n",
    "\n",
    "The idea comes from [Science Projects: Asteroid Mining](https://www.sciencebuddies.org/science-fair-projects/project-ideas/Astro_p038/astronomy/asteroid-mining-gold-rush-in-space).\n",
    "\n",
    "There are about 1.2 million asteroid data in the [NASA JPL Small-Body Database](https://ssd.jpl.nasa.gov/tools/sbdb_lookup.html#/), however not every data has complete parameters.\n",
    "\n",
    "We will use several orbital parameters, asteroid size, and bulk albedo to predict possible spectral classifications. It is actually a classification challenge, KNN is used here since the number of data points with known spectral type is less than 1000 in the JPL data set.\n",
    "\n",
    "Then, I use MCMC to find the best parameters. Science Projects: Asteroid Mining\n",
    "\n",
    "2) MCMC Mcfost:\n",
    "\n",
    "My current research topic is exoplanetary system disk modeling, which could be essential to model the performance of coronagraphs, like Roman CGI.\n",
    "\n",
    "In this chapter, we will introduce what Mcfost does, and how to modify the parameters with the para file. Then, we will use the MCMC method to figure out the best-fitting para file.\n",
    "\n",
    "RZ Psc will be used as an example in the simulation, see [dreamjade/mcfost-python](https://github.com/dreamjade/mcfost-python) for detail.\n",
    "\n",
    "3) Flavor transformation Collision-term:\n",
    "\n",
    "In this chapter, we will discuss monochromatic Collision-induced flavor instability.\n",
    "\n",
    "See [dreamjade/CollisionTerm](https://github.com/dreamjade/CollisionTerm) for detail.\n",
    "\n",
    "4) Asteroid Mass Estimator (backup topic):\n",
    "\n",
    "There has been little quantitative analysis of asteroid masses in the NASA JPL dataset,  the majority of the data points lack GM values. That is because an accurate asteroid masses estimation usually requires close encounters or high-accuracy orbit observation of a multiple-body system. However, mass is one of the most crucial asteroid features. One may determine the potential interior composition of an asteroid by combining its mass and size. The makeup of asteroids is a reflection of the accretion and collisional environment that existed in the early solar system. Therefore, it could be useful if we could predict the possible mass from the known parameters. In this part, we will build a neural network to give the possible mass range of asteroids with unknown mass. Similar concepts have been discussed in [Agnan 2021](https://www.sciencedirect.com/science/article/pii/S0273117721004622). \n",
    "\n",
    "However, considering that quality is affected by multiple observables, only 15 GM data points are likely to be insufficient for even the most preliminary analysis. As a result, we need to gather information from papers about asteroid masses. mass estimates could be done according to orbital deflections during close encounters ([Michalak 2000](https://articles.adsabs.harvard.edu/pdf/2000A%26A...360..363M), [2001](https://www.aanda.org/articles/aa/pdf/2001/29/aa10228.pdf); [Zielenbach 2011](https://iopscience.iop.org/article/10.1088/0004-6256/142/4/120/pdf)), planetary ephemerides ([Baer & Chesley 2008](https://link.springer.com/content/pdf/10.1007/s10569-007-9103-8.pdf); [Baer et al. 2011](https://iopscience.iop.org/article/10.1088/0004-6256/141/5/143/pdf); [Fienga et al. 2008](https://www.aanda.org/articles/aa/pdf/2008/49/aa6607-06.pdf), [2009](https://www.aanda.org/articles/aa/pdf/2009/45/aa11755-09.pdf), [2014](https://arxiv.org/pdf/1405.0484.pdf)), and a comprehensive review of prior research ([Density of asteroids by B. Carry](https://arxiv.org/pdf/1203.4336.pdf)). There are also some recently results based on the data from ESA Gaia mission ([Siltala & Granvik 2021A](https://www.aanda.org/articles/aa/full_html/2022/02/aa41459-21/aa41459-21.html),[2021B](https://iopscience.iop.org/article/10.3847/2041-8213/abe948)) .\n",
    "\n",
    "Additionally, as the volume is the third power of the dimension, the inferred mass error could result from inaccurate dimensions, which would result in a threefold increase in the error ([Hanu≈° et al. 2017](https://www.aanda.org/component/article?access=doi&doi=10.1051/0004-6361/201629956#R32)).\n",
    "\n",
    "5) Other Useful Links:\n",
    "\n",
    "[List of exceptional asteroids on Wiki](https://en.wikipedia.org/wiki/List_of_exceptional_asteroids)\n",
    "\n",
    "[Using Bayesian Deep Learning to Infer Planet Mass from Gaps in Protoplanetary Disks](https://iopscience.iop.org/article/10.3847/1538-4357/ac7a3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175c89e-e50e-4587-8472-e428e12d5e25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 Asteroid Spectral Classification Estimator\n",
    "\n",
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bc38331-88ca-4ece-8065-513d162d7338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T07:24:13.767042Z",
     "iopub.status.busy": "2022-12-04T07:24:13.766837Z",
     "iopub.status.idle": "2022-12-04T07:24:16.220207Z",
     "shell.execute_reply": "2022-12-04T07:24:16.219714Z",
     "shell.execute_reply.started": "2022-12-04T07:24:13.767028Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of column names:  ['spec_B', 'spec_T', 'full_name', 'diameter', 'extent', 'albedo', 'a', 'q', 'i', 'GM', 'rot_per', 'BV', 'UB', 'IR']\n",
      "Total data point number: 1242581\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#opening the csv file by specifying\n",
    "with open('sbdb_asteroids.csv') as csv_file:\n",
    "    # Creating an object of csv reader\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    columns = []\n",
    " \n",
    "    # loop to iterate through the rows of csv\n",
    "    for row in csv_reader:\n",
    "        # Write columns\n",
    "        columns.append(row)\n",
    "# printing the result\n",
    "column_names = columns[0]\n",
    "print(\"List of column names: \", columns[0])\n",
    "print(\"Total data point number: \"+ str(len(columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "5684952a-3562-40ae-95ff-1b955da23aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:36:53.936336Z",
     "iopub.status.busy": "2022-12-07T16:36:53.936102Z",
     "iopub.status.idle": "2022-12-07T16:36:55.704894Z",
     "shell.execute_reply": "2022-12-07T16:36:55.704431Z",
     "shell.execute_reply.started": "2022-12-07T16:36:53.936322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data with known spec_B: 1666\n",
      "The number of data with known spec_T: 980\n",
      "The number of data with known full_name: 1242580\n",
      "The number of data with known diameter: 139680\n",
      "The number of data with known extent: 20\n",
      "The number of data with known albedo: 138546\n",
      "The number of data with known a: 1242580\n",
      "The number of data with known q: 1242580\n",
      "The number of data with known i: 1242580\n",
      "The number of data with known GM: 15\n",
      "The number of data with known rot_per: 33350\n",
      "The number of data with known BV: 1021\n",
      "The number of data with known UB: 979\n",
      "The number of data with known IR: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(column_names)):\n",
    "    non_empty_number = 0\n",
    "    for data in columns[1:]:\n",
    "        if data[i] !='':\n",
    "            non_empty_number += 1\n",
    "    print(\"The number of data with known \"+column_names[i]+\": \"+ str(non_empty_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "6ba7031e-d53a-479d-9dbd-38fb7c592670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:45:25.452632Z",
     "iopub.status.busy": "2022-12-07T16:45:25.452388Z",
     "iopub.status.idle": "2022-12-07T16:45:25.851921Z",
     "shell.execute_reply": "2022-12-07T16:45:25.851396Z",
     "shell.execute_reply.started": "2022-12-07T16:45:25.452617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 1240914, 'S': 445, 'C': 152, 'Ch': 139, 'X': 138, 'Sq': 114, 'Xc': 67, 'B': 66, 'Sl': 56, 'Xk': 48, 'V': 48, 'L': 41, 'Sa': 38, 'Cb': 37, 'K': 37, 'Xe': 30, 'Sk': 29, 'Sr': 27, 'Q': 20, 'T': 19, 'A': 17, 'S:': 16, 'Cgh': 15, 'Ld': 15, 'D': 13, 'Cg': 9, 'O': 7, 'X:': 6, 'R': 5, 'U': 4, 'C:': 3, 'Sq:': 2, 'V:': 1, 'K:': 1, 'S(IV)': 1}\n"
     ]
    }
   ],
   "source": [
    "# Spec_B list\n",
    "spec_B_list = [i[0] for i in columns[1:]]\n",
    "\n",
    "# Get the set of all possible elements in the list\n",
    "all_elements = set(spec_B_list)\n",
    "\n",
    "# Count the number of times each element appears\n",
    "counts = {}\n",
    "for elem in all_elements:\n",
    "    counts[elem] = spec_B_list.count(elem)\n",
    "\n",
    "# Print the counts\n",
    "sorted_counts = dict(sorted(counts.items(), key=lambda x: x[1], reverse=True))\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c294c5a-1a90-487c-8c7b-ca2b64c812c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Asteroid spectral types (SMASS, \"spec_B\")\n",
    "\n",
    "reference: [wiki/Asteroid_spectral_types](https://en.wikipedia.org/wiki/Asteroid_spectral_types)\n",
    "\n",
    "SMASS(\"spec_B\" based on spectral features from 0.44 Œºm to 0.92 Œºm) is chosen as the target since it doesn't base on the albedo and we have more data points with this value. Here, instead of using detailed classification, I adopted 3 big groups and other as spectral classification.\n",
    "\n",
    "Below is the information for the 3 major groups:\n",
    "\n",
    "1) C-group: \n",
    "\n",
    "Carbon-based objects, including 'C','Ch','B','Cb','Cgh','Cg','C:' in the data set.\n",
    "\n",
    "2) S-group:\n",
    "\n",
    "Silicate majored objects, including 'S','Sq','Sl','L','Sa','K','Sk','Sr','Q','A','S:','R','Sq:','K:','S(IV)' in the data set.\n",
    "\n",
    "3) X-group: \n",
    "\n",
    "Mostly metallic objects, including 'X','Xc','Xk','Xe','X:' in the data set..\n",
    "\n",
    "4) Other: \n",
    "\n",
    "Whose spectrum cannot classification into the previous three groups, including 'V','T','Ld','D','O','U','V:' in the data set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd16c8c-da77-4788-b0b9-472cfd3f0585",
   "metadata": {},
   "source": [
    "### knn codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "0dc7ee65-5be8-4374-bed8-b285f7b4f185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T01:28:03.031452Z",
     "iopub.status.busy": "2022-12-07T01:28:03.031226Z",
     "iopub.status.idle": "2022-12-07T01:28:03.038439Z",
     "shell.execute_reply": "2022-12-07T01:28:03.037986Z",
     "shell.execute_reply.started": "2022-12-07T01:28:03.031432Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Define the k-NN algorithm\n",
    "def knn(X, y, x, k, std_adj = np.array([0.51701419,0.20836071,0.32275631,0.40417267]), q=2.5, r= 2):\n",
    "    # Normalize the data\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    X_std[1:] = X_std[1:]*std_adj # wighted by changing the std\n",
    "    X_norm = (X - X_mean) / X_std\n",
    "    x_norm = (x - X_mean) / X_std\n",
    "    \n",
    "    # Compute the Minkowski distances between x and all points in X\n",
    "    distances = distance.cdist (x_norm.reshape(1, -1), X_norm, 'minkowski', p=q)[0]\n",
    "    \n",
    "    # Sort the distances and the corresponding labels\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    sorted_distances = distances[sorted_indices]\n",
    "    sorted_labels = y[sorted_indices]\n",
    "    \n",
    "    #Check if inside the data points\n",
    "    if not sorted_distances[0]:\n",
    "        #print(\"in train data\")\n",
    "        return sorted_labels[0]\n",
    "    \n",
    "    # Take the k-nearest neighbors\n",
    "    nearest_neighbors = sorted_labels[:k]\n",
    "\n",
    "    # Compute the weights based on the distances\n",
    "    weights = 1 / sorted_distances[:k]**r\n",
    "\n",
    "    # Normalize the weights\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    # Compute the weighted average of the labels\n",
    "    predicted_label = np.dot(nearest_neighbors.T, weights)\n",
    "    \n",
    "    # Maximize\n",
    "    final_predicted = np.zeros(len(predicted_label))\n",
    "    final_predicted[np.argmax(predicted_label)] = 1\n",
    "    \n",
    "    return final_predicted\n",
    "\n",
    "def knn_mul(X, y, x, k, std_adj = np.array([1,1,1,1]), q=2, r= 2):\n",
    "    # output\n",
    "    final_predicted = np.zeros((x.shape[0], y.shape[1]))\n",
    "    \n",
    "    # Normalize the data\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    X_std[1:] = X_std[1:]*std_adj # wighted by changing the std\n",
    "    X_norm = (X - X_mean) / X_std\n",
    "    x_norm = (x - X_mean) / X_std\n",
    "    \n",
    "    # Compute the Minkowski distances between x and all points in X\n",
    "    distances = distance.cdist (x_norm, X_norm, 'minkowski', p=q)\n",
    "    \n",
    "    # Sort the distances and the corresponding labels\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    sorted_distances = distances[np.arange(distances.shape[0])[:, None], sorted_indices]\n",
    "    ys = np.tile(y, (len(x),1,1))\n",
    "    sorted_labels = ys[np.arange(ys.shape[0])[:, None], sorted_indices]\n",
    "    # Take the k-nearest neighbors\n",
    "    nearest_neighbors = sorted_labels[:,:k]\n",
    "\n",
    "    # Compute the weights based on the distances\n",
    "    nearest_distances = sorted_distances[:,:k]\n",
    "    weights = (np.linalg.norm(nearest_distances, ord=-r, axis=-1)[:, np.newaxis] / nearest_distances)**r\n",
    "\n",
    "    # Compute the weighted average of the labels\n",
    "    for i in range(x.shape[0]):\n",
    "        predicted_label = np.dot(nearest_neighbors[i].T, weights[i])\n",
    "        # Maximize\n",
    "        final_predicted[i, np.argmax(predicted_label)] = 1\n",
    "    \n",
    "    return final_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62debb-0339-49a9-ab3e-310a83ec49be",
   "metadata": {},
   "source": [
    "#### Before mcmc, using normalization and Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "727180fc-310b-459e-b1bd-4c99b7a9bd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:47:10.597627Z",
     "iopub.status.busy": "2022-12-07T16:47:10.597388Z",
     "iopub.status.idle": "2022-12-07T16:47:11.909173Z",
     "shell.execute_reply": "2022-12-07T16:47:11.908812Z",
     "shell.execute_reply.started": "2022-12-07T16:47:10.597612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 72.062%\n"
     ]
    }
   ],
   "source": [
    "# Spec_B list\n",
    "paraB = [[i[3], i[5], i[6], i[7], i[8]] for i in columns[1:] if '' not in [i[0], i[3], i[5], i[6], i[7], i[8]]]\n",
    "dataB = [i[0] for i in columns[1:] if '' not in [i[0], i[3], i[5], i[6], i[7], i[8]]]\n",
    "\n",
    "#[C,S,X,O]\n",
    "dataB_number_ratio = [1, 1, 1]\n",
    "dataB_number = [[1,0,0,0] if i in ['C','Ch','B','Cb','Cgh','Cg','C:'] else i for i in dataB]\n",
    "dataB_number = [[0,dataB_number_ratio[0],0,0] if i in ['S','Sq','Sl','L','Sa','K','Sk','Sr','Q','A','S:','R','Sq:','K:','S(IV)'] else i for i in dataB_number]\n",
    "dataB_number = [[0,0,dataB_number_ratio[1],0] if i in ['X','Xc','Xk','Xe','X:'] else i for i in dataB_number]\n",
    "dataB_number = [[0,0,0,dataB_number_ratio[2]] if i in ['V','T','Ld','D','O','U','V:'] else i for i in dataB_number]\n",
    "\n",
    "# Define the training data\n",
    "X = np.array([[float(j) for j in i] for i in paraB])\n",
    "y = np.array(dataB_number)\n",
    "\n",
    "# print prob\n",
    "def print_prob(prob_list):\n",
    "    print('C: '+'{:.2%}'.format(prob_list[0]))\n",
    "    print('S: '+'{:.2%}'.format(prob_list[1]))\n",
    "    print('X: '+'{:.2%}'.format(prob_list[2]))\n",
    "    print('O: '+'{:.2%}'.format(prob_list[3]))\n",
    "\n",
    "# Define the test point\n",
    "x = [[i[3], i[5], i[6], i[7], i[8]] for i in columns[1:] if '' not in [i[3], i[5], i[6], i[7], i[8]]]\n",
    "x = np.array([[float(j) for j in i] for i in x])\n",
    "#predicted_label = knn(X, y, x[15600], k=5)\n",
    "#print_prob(predicted_label)\n",
    "\n",
    "# print accuaracy table\n",
    "def accu_tab(fact, predict):\n",
    "    if fact.shape!=predict.shape:\n",
    "        return 0\n",
    "    table_size = len(predict[0])\n",
    "    accu_tab = np.zeros([table_size,table_size])\n",
    "    for i in range(len(predict)):\n",
    "        accu_tab = accu_tab + np.outer(fact[i], predict[i])\n",
    "    return accu_tab/len(predict)\n",
    "\n",
    "# Run cross-validation to evaluate the performance of the k-NN algorithm\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = []\n",
    "accu_tabs = []\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    #print(len(train_index), len(test_index))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_test = np.array([[1 if j !=0 else 0 for j in i] for i in y_test]) # normalize y_test\n",
    "    predicted_labels = knn_mul(X_train, y_train, X_test, 23, np.array([1,1,1,1]), 2, 1)\n",
    "    score = np.sum(np.apply_along_axis(np.average,1,(y_test*predicted_labels).T))\n",
    "    # Print the accuaracy matrix as percentages\n",
    "    accu_tabs.append(accu_tab(y_test, predicted_labels))\n",
    "    scores.append(score)\n",
    "\n",
    "# Print the mean accuracy of the k-NN algorithm\n",
    "print('Mean Accuracy: '+'{:.3%}'.format(np.mean(scores)))\n",
    "# Configure the NumPy printing options\n",
    "#np.set_printoptions(formatter={'float': '{: 0.3%}'.format})\n",
    "#np.set_printoptions(threshold=1000, edgeitems=3, linewidth=75, precision=8, suppress=False, nanstr='nan', infstr='inf', formatter=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514be71-cb7e-405b-a5cf-1340f177f5fc",
   "metadata": {},
   "source": [
    "#### After mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "14ebf835-043f-443b-9a94-17c2671df0a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T15:58:34.023084Z",
     "iopub.status.busy": "2022-12-07T15:58:34.022876Z",
     "iopub.status.idle": "2022-12-07T15:58:34.915702Z",
     "shell.execute_reply": "2022-12-07T15:58:34.915176Z",
     "shell.execute_reply.started": "2022-12-07T15:58:34.023069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 74.415%\n"
     ]
    }
   ],
   "source": [
    "# Spec_B list\n",
    "paraB = [[i[3], i[5], i[6], i[7], i[8]] for i in columns[1:] if '' not in [i[0], i[3], i[5], i[6], i[7], i[8]]]\n",
    "dataB = [i[0] for i in columns[1:] if '' not in [i[0], i[3], i[5], i[6], i[7], i[8]]]\n",
    "\n",
    "#[C,S,X,O]\n",
    "dataB_number_ratio = [0.80611106,   0.85283428,   0.63251724]\n",
    "dataB_number = [[1,0,0,0] if i in ['C','Ch','B','Cb','Cgh','Cg','C:'] else i for i in dataB]\n",
    "dataB_number = [[0,dataB_number_ratio[0],0,0] if i in ['S','Sq','Sl','L','Sa','K','Sk','Sr','Q','A','S:','R','Sq:','K:','S(IV)'] else i for i in dataB_number]\n",
    "dataB_number = [[0,0,dataB_number_ratio[1],0] if i in ['X','Xc','Xk','Xe','X:'] else i for i in dataB_number]\n",
    "dataB_number = [[0,0,0,dataB_number_ratio[2]] if i in ['V','T','Ld','D','O','U','V:'] else i for i in dataB_number]\n",
    "\n",
    "# Define the training data\n",
    "X = np.array([[float(j) for j in i] for i in paraB])\n",
    "y = np.array(dataB_number)\n",
    "\n",
    "# print prob\n",
    "def print_prob(prob_list):\n",
    "    print('C: '+'{:.2%}'.format(prob_list[0]))\n",
    "    print('S: '+'{:.2%}'.format(prob_list[1]))\n",
    "    print('X: '+'{:.2%}'.format(prob_list[2]))\n",
    "    print('O: '+'{:.2%}'.format(prob_list[3]))\n",
    "\n",
    "# Define the test point\n",
    "x = [[i[3], i[5], i[6], i[7], i[8]] for i in columns[1:] if '' not in [i[3], i[5], i[6], i[7], i[8]]]\n",
    "x = np.array([[float(j) for j in i] for i in x])\n",
    "#predicted_label = knn(X, y, x[15600], k=5)\n",
    "#print_prob(predicted_label)\n",
    "\n",
    "# print accuaracy table\n",
    "def accu_tab(fact, predict):\n",
    "    if fact.shape!=predict.shape:\n",
    "        return 0\n",
    "    table_size = len(predict[0])\n",
    "    accu_tab = np.zeros([table_size,table_size])\n",
    "    for i in range(len(predict)):\n",
    "        accu_tab = accu_tab + np.outer(fact[i], predict[i])\n",
    "    return accu_tab/len(predict)\n",
    "\n",
    "# Run cross-validation to evaluate the performance of the k-NN algorithm\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = []\n",
    "accu_tabs = []\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    #print(len(train_index), len(test_index))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_test = np.array([[1 if j !=0 else 0 for j in i] for i in y_test]) # normalize y_test\n",
    "    predicted_labels = knn_mul(X_train, y_train, X_test, 23, np.array([0.93,1.10,1.19,1.53]), 0.96, 1.38)\n",
    "    score = np.sum(np.apply_along_axis(np.average,1,(y_test*predicted_labels).T))\n",
    "    # Print the accuaracy matrix as percentages\n",
    "    accu_tabs.append(accu_tab(y_test, predicted_labels))\n",
    "    scores.append(score)\n",
    "\n",
    "# Print the mean accuracy of the k-NN algorithm\n",
    "print('Mean Accuracy: '+'{:.3%}'.format(np.mean(scores)))\n",
    "# Configure the NumPy printing options\n",
    "#np.set_printoptions(formatter={'float': '{: 0.3%}'.format})\n",
    "#np.set_printoptions(threshold=1000, edgeitems=3, linewidth=75, precision=8, suppress=False, nanstr='nan', infstr='inf', formatter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "8c2c56d6-9ac7-410e-ba42-ee3f1bad83b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T15:58:35.554814Z",
     "iopub.status.busy": "2022-12-07T15:58:35.554604Z",
     "iopub.status.idle": "2022-12-07T15:58:35.558979Z",
     "shell.execute_reply": "2022-12-07T15:58:35.558621Z",
     "shell.execute_reply.started": "2022-12-07T15:58:35.554799Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\\E    C       S       X      O\n",
      "-----  ------  ------  -----  -----\n",
      "C      26.59%  1.57%   0.64%  0.00%\n",
      "S      1.85%   44.47%  0.93%  0.07%\n",
      "X      8.91%   6.20%   2.85%  0.07%\n",
      "O      1.71%   3.20%   0.43%  0.50%\n"
     ]
    }
   ],
   "source": [
    "# Python program to understand the usage of tabulate function for printing tables in a tabular format\n",
    "from tabulate import tabulate\n",
    "titles = [\"C\", \"S\", \"X\", \"O\"]\n",
    "accu_tabs_mean=np.mean(accu_tabs, axis=0)\n",
    "accu_tabs_p = []\n",
    "for i in range(len(titles)):\n",
    "    accu_tabs_p.append([titles[i]]+[format(x, '.2%') for x in accu_tabs_mean[i]])\n",
    "print (tabulate(accu_tabs_p, headers=[\"O\\E\",\"C\", \"S\", \"X\", \"O\"]))\n",
    "#print(np.trace(np.mean(accu_tabs, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "8e6dea3f-9cf5-44ea-92eb-3afcc634a769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:49:05.697800Z",
     "iopub.status.busy": "2022-12-07T16:49:05.697564Z",
     "iopub.status.idle": "2022-12-07T16:49:34.818015Z",
     "shell.execute_reply": "2022-12-07T16:49:34.817595Z",
     "shell.execute_reply.started": "2022-12-07T16:49:05.697785Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_980889/3851234169.py:69: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = (np.linalg.norm(nearest_distances, ord=-r, axis=-1)[:, np.newaxis] / nearest_distances)**r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 60.29%\n",
      "S: 35.71%\n",
      "X: 3.22%\n",
      "O: 0.77%\n"
     ]
    }
   ],
   "source": [
    "# type * happens prob\n",
    "predicted_labels = knn_mul(X_train, y_train, x, 25, np.array([0.88,1.2,0.68,0.95]), 0.7, 1.5)\n",
    "print_prob(np.apply_along_axis(np.average,1,np.array(predicted_labels).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917fcf8e-3987-4791-9048-666918a40aa4",
   "metadata": {},
   "source": [
    "#### MCMC part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "f5d1c327-f3fa-484a-8e27-f1ec5921b321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T01:28:17.777122Z",
     "iopub.status.busy": "2022-12-07T01:28:17.776885Z",
     "iopub.status.idle": "2022-12-07T01:28:17.779842Z",
     "shell.execute_reply": "2022-12-07T01:28:17.779358Z",
     "shell.execute_reply.started": "2022-12-07T01:28:17.777109Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#record best\n",
    "best_sol_dir='knn_best.npy'\n",
    "#np.save(best_sol_dir, np.array([-31.97546022138345,0.5,0.5,0.5,0.5,1,1,1,39,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "1b63199e-cb6b-471d-a1ba-7e25b6009293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T01:28:23.315062Z",
     "iopub.status.busy": "2022-12-07T01:28:23.314854Z",
     "iopub.status.idle": "2022-12-07T01:28:23.320837Z",
     "shell.execute_reply": "2022-12-07T01:28:23.320477Z",
     "shell.execute_reply.started": "2022-12-07T01:28:23.315047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import emcee\n",
    "def lnlike(theta):\n",
    "    std_adj = theta[:4]\n",
    "    number_mul = theta[4:7]\n",
    "    k = int(theta[7])\n",
    "    q = theta[8]\n",
    "    r = theta[9]\n",
    "    #[C,S,X,O]\n",
    "    dataB_number = [[1,0,0,0] if i in ['C','Ch','B','Cb','Cgh','Cg','C:'] else i for i in dataB]\n",
    "    dataB_number = [[0,number_mul[0],0,0] if i in ['S','Sq','Sl','L','Sa','K','Sk','Sr','Q','A','S:','R','Sq:','K:','S(IV)'] else i for i in dataB_number]\n",
    "    dataB_number = [[0,0,number_mul[1],0] if i in ['X','Xc','Xk','Xe','X:'] else i for i in dataB_number]\n",
    "    dataB_number = [[0,0,0,number_mul[2]] if i in ['V','T','Ld','D','O','U','V:'] else i for i in dataB_number]\n",
    "\n",
    "    # Define the training data\n",
    "    X = np.array([[float(j) for j in i] for i in paraB])\n",
    "    y = np.array(dataB_number)\n",
    "\n",
    "    # Run cross-validation to evaluate the performance of the k-NN algorithm\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    scores = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        #print(len(train_index), len(test_index))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        y_test = np.array([[1 if j !=0 else 0 for j in i] for i in y_test]) # normalize y_test\n",
    "        predicted_labels = knn_mul(X_train, y_train, X_test, k, std_adj,q,r)\n",
    "        score = np.sum(np.apply_along_axis(np.average,1,(y_test*predicted_labels).T))\n",
    "        scores.append(score)\n",
    "    output = 100*np.log(np.mean(scores))\n",
    "    global best_sol_dir\n",
    "    try:best_sol = np.load(best_sol_dir,)\n",
    "    except:return(output)\n",
    "    if output>best_sol[0]:\n",
    "        best_sol[0]=output\n",
    "        best_sol[1:]=theta\n",
    "        print(best_sol)\n",
    "        np.save(best_sol_dir, best_sol)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "56370207-dfe0-4dbb-8ced-35ce19996d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T01:28:24.054541Z",
     "iopub.status.busy": "2022-12-07T01:28:24.054364Z",
     "iopub.status.idle": "2022-12-07T01:28:24.057817Z",
     "shell.execute_reply": "2022-12-07T01:28:24.057477Z",
     "shell.execute_reply.started": "2022-12-07T01:28:24.054527Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lnprior(theta):\n",
    "    '''\n",
    "    if theta[7]<1 or theta[7]>100:\n",
    "        return -np.inf\n",
    "    for i in theta[:7]:\n",
    "        if i<0.2 or i>5:\n",
    "            return -np.inf\n",
    "    for i in theta[8:10]:\n",
    "        if i<0.2 or i>5:\n",
    "            return -np.inf\n",
    "    '''\n",
    "    global pos0\n",
    "    if distance.minkowski(np.delete(theta, -3), np.delete(pos0, -3), 1)>0.5:\n",
    "        return -np.inf\n",
    "    if theta[7]<1 or theta[7]>100:\n",
    "        return -np.inf\n",
    "    return 0\n",
    "\n",
    "def lnprob(theta):\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "89286674-bce5-4e5e-b8c8-5316ee1991af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T01:28:53.243809Z",
     "iopub.status.busy": "2022-12-07T01:28:53.243573Z",
     "iopub.status.idle": "2022-12-07T01:28:53.247490Z",
     "shell.execute_reply": "2022-12-07T01:28:53.247128Z",
     "shell.execute_reply.started": "2022-12-07T01:28:53.243795Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#random position\n",
    "pos0 = np.array([0.91158577,  1.03691   ,  1.18240536,  1.5094504 ,  0.76005638,\n",
    "        0.90478132,  0.6032742 , 23.56535226,  0.97658515,  1.40117865])\n",
    "pos = np.random.rand(1024, 10)*[0.05,0.05,0.05,0.05,0.05,0.05,0.05,30,0.05,0.05]+pos0\n",
    "#pos = np.random.rand(1024, 10)*[4.8,4.8,4.8,4.8,4.8,4.8,4.8,99,4.8,4.8]+np.ones((1024, 10))*[0.2,0.2,0.2,0.2,0.2,0.2,0.2,1,0.2,0.2]\n",
    "#pos[0] = np.array([0.5,0.5,0.5,0.5,1,1,1,39,2,2])\n",
    "nwalkers, ndim = pos.shape\n",
    "filename = \"Best_fit_knn.h5\"\n",
    "knn_backend = emcee.backends.HDFBackend(filename, name=\"Best_fit_knn\")\n",
    "# Don't forget to clear it in case the file already exists\n",
    "#mcfost_backend.reset(nwalkers, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dded75-26ec-4ca3-a62e-08e36471b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run mcmc\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"\n",
    "steps = 6000\n",
    "with Pool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, pool=pool, backend=knn_backend)\n",
    "    sampler.run_mcmc(pos, steps, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ff250-5984-41de-a3cc-ca18c4e3ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(10, figsize=(10, 30), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "labels = ['std_adj','std_adj','std_adj','std_adj','number_mul','number_mul','number_mul','k','q','r']\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "axes[-1].set_xlabel(\"step number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf1925-4665-440b-9b17-c436e262fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.get_autocorr_time(tol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07304b-451d-45b1-aa2a-b77267849e38",
   "metadata": {},
   "source": [
    "sampler.get_autocorr_time(tol=0)\n",
    "\n",
    "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16000/16000 [27:00:51<00:00,  6.08s/it]\n",
    "\n",
    "Detailed performance metrics for this job will be available at https://metrics.hpc.arizona.edu/#job_viewer?action=show&realm=SUPREMM&resource_id=73&local_job_id=5794790 by 8am on 2022/12/08."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
